#pragma kernel DepthToWorld
#pragma kernel CalculateVelocity
#pragma kernel ProcessConfidence

// Input textures
Texture2D<float> _HumanDepth;
Texture2D<float> _HumanStencil;
Texture2D<float> _EnvDepth;
Texture2D<float4> _CameraTexture;

// Output textures
RWTexture2D<float4> _PositionRT;
RWTexture2D<float4> _VelocityRT;
RWTexture2D<float> _ConfidenceRT;

// Previous frame data for velocity calculation
Texture2D<float4> _PreviousPositionRT;

// Matrices
float4x4 _InvVPMatrix;
float4x4 _CameraToWorld;
float4x4 _ProjectionMatrix;

// Parameters
float4 _DepthRange; // x: near, y: far
float _DeltaTime;
float3 _LeftHandVelocity;
float3 _RightHandVelocity;

// Samplers
SamplerState sampler_LinearClamp;

// Convert depth to world position using ray-based approach (Keijiro/Metavido pattern)
// This avoids confusing Y-flip issues by using camera intrinsics directly
float3 DepthToWorldPos(float2 uv, float depth)
{
    // Ray-based unprojection: UV [0,1] â†’ ray direction
    // For clip-space approach, we need to flip Y because:
    // - UV has origin at top-left (Y=0 at top)
    // - Clip space has Y-up (Y=-1 at bottom, Y=+1 at top)
    float2 clipXY = float2(uv.x * 2.0 - 1.0, 1.0 - uv.y * 2.0);
    float4 clipPos = float4(clipXY, depth, 1.0);
    
    // Transform to world space
    float4 worldPos = mul(_InvVPMatrix, clipPos);
    
    // Perspective divide (guard against zero)
    worldPos.xyz /= max(abs(worldPos.w), 0.0001);
    
    return worldPos.xyz;
}

// Main kernel: Convert depth to world position
[numthreads(8, 8, 1)]
void DepthToWorld(uint3 id : SV_DispatchThreadID)
{
    // Get texture dimensions
    uint2 dimensions;
    _PositionRT.GetDimensions(dimensions.x, dimensions.y);
    
    if (id.x >= dimensions.x || id.y >= dimensions.y)
        return;
    
    // Calculate UV coordinates
    float2 uv = (float2(id.xy) + 0.5) / float2(dimensions);
    
    // Sample textures
    float humanDepth = _HumanDepth.SampleLevel(sampler_LinearClamp, uv, 0).r;
    float stencil = _HumanStencil.SampleLevel(sampler_LinearClamp, uv, 0).r;
    
    // Initialize output
    float4 position = float4(0, 0, 0, 0);
    
    // Process human depth if stencil is valid
    if (stencil > 0.5)
    {
        // Normalize depth value
        float normalizedDepth = humanDepth;
        
        // Convert to world position
        float3 worldPos = DepthToWorldPos(uv, normalizedDepth);
        
        // Apply depth range
        float depthInRange = saturate((length(worldPos) - _DepthRange.x) / (_DepthRange.y - _DepthRange.x));
        
        position = float4(worldPos, depthInRange);
    }
    else if (_EnvDepth.SampleLevel(sampler_LinearClamp, uv, 0).r > 0)
    {
        // Fall back to environment depth if available
        float envDepth = _EnvDepth.SampleLevel(sampler_LinearClamp, uv, 0).r;
        float3 worldPos = DepthToWorldPos(uv, envDepth);
        position = float4(worldPos, 0.0); // Mark as environment
    }
    
    _PositionRT[id.xy] = position;
}

// Calculate velocity from position changes
[numthreads(8, 8, 1)]
void CalculateVelocity(uint3 id : SV_DispatchThreadID)
{
    uint2 dimensions;
    _VelocityRT.GetDimensions(dimensions.x, dimensions.y);
    
    if (id.x >= dimensions.x || id.y >= dimensions.y)
        return;
    
    // Get current and previous positions
    float4 currentPos = _PositionRT[id.xy];
    float4 previousPos = _PreviousPositionRT[id.xy];
    
    float3 velocity = float3(0, 0, 0);
    
    // Calculate velocity if both positions are valid
    if (currentPos.w > 0 && previousPos.w > 0)
    {
        velocity = (currentPos.xyz - previousPos.xyz) / _DeltaTime;
        
        // Apply hand velocity influence based on proximity
        float2 uv = (float2(id.xy) + 0.5) / float2(dimensions);
        
        // Left side influenced by left hand, right side by right hand
        if (uv.x < 0.5)
        {
            float influence = 1.0 - (uv.x * 2.0); // Stronger on left edge
            velocity = lerp(velocity, _LeftHandVelocity, influence * 0.3);
        }
        else
        {
            float influence = (uv.x - 0.5) * 2.0; // Stronger on right edge
            velocity = lerp(velocity, _RightHandVelocity, influence * 0.3);
        }
        
        // Clamp velocity to reasonable values
        velocity = clamp(velocity, -10.0, 10.0);
    }
    
    _VelocityRT[id.xy] = float4(velocity, length(velocity));
}

// Process confidence values for adaptive quality
[numthreads(8, 8, 1)]
void ProcessConfidence(uint3 id : SV_DispatchThreadID)
{
    uint2 dimensions;
    _ConfidenceRT.GetDimensions(dimensions.x, dimensions.y);
    
    if (id.x >= dimensions.x || id.y >= dimensions.y)
        return;
    
    float2 uv = (float2(id.xy) + 0.5) / float2(dimensions);
    
    // Sample stencil as confidence base
    float confidence = _HumanStencil.SampleLevel(sampler_LinearClamp, uv, 0).r;
    
    // Reduce confidence at edges
    float2 edgeDist = min(uv, 1.0 - uv);
    float edgeFactor = saturate(min(edgeDist.x, edgeDist.y) * 10.0);
    confidence *= edgeFactor;
    
    // Reduce confidence for fast-moving areas
    float velocity = _VelocityRT[id.xy].w;
    float velocityFactor = 1.0 - saturate(velocity / 5.0);
    confidence *= velocityFactor;
    
    _ConfidenceRT[id.xy] = confidence;
}